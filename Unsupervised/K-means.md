# KMeans
- K-means é‹ä½œçš„æµç¨‹æ­¥é©Ÿï¼š
  - 1.é¦–å…ˆè¨­å®šè¦åˆ†æˆå¤šå°‘ç¾¤ï¼šK
  - 2.ç„¶å¾Œåœ¨ç‰¹å¾µç©ºé–“ä¸­éš¨æ©Ÿè¨­å®šKå€‹ç¾¤å¿ƒã€‚
  - 3.è¨ˆç®—æ¯ä¸€å€‹è³‡æ–™é»åˆ°Kå€‹ç¾¤å¿ƒçš„è·é›¢ ( åŸºæœ¬ä¸Šä½¿ç”¨ L2è·é›¢ï¼Œä½†ä¹Ÿæ˜¯å¯ä»¥æ›æˆåˆ¥çš„ã€‚)
  - 4.å°‡è³‡æ–™é»åˆ†çµ¦è·é›¢æœ€è¿‘çš„é‚£å€‹ç¾¤å¿ƒã€‚
  - 5.åœ¨æ‰€æœ‰è³‡æ–™é»éƒ½åˆ†é…å®Œç•¢å¾Œï¼Œæ¯ä¸€ç¾¤å†ç”¨å‰›å‰›åˆ†é…åˆ°çš„è³‡æ–™é»ç®—å¹³å‡(means)ä¾†æ›´æ–°ç¾¤å¿ƒã€‚
  - 6.æœ€å¾Œä¸æ–·é‡è¤‡3â€“5 çš„å‹•ä½œï¼Œç›´åˆ°æ”¶æ–‚ ( æ¯æ¬¡æ›´æ–°å¾Œç¾¤å¿ƒéƒ½å·²ç¶“ä¸å¤ªæœƒè®Šå‹• ) å¾ŒçµæŸã€‚
- ğŸ‘[Understanding K-Means, K-Means++ and, K-Medoids Clustering Algorithms](https://towardsdatascience.com/understanding-k-means-k-means-and-k-medoids-clustering-algorithms-ad9c9fbf47ca)
# [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
```python
from sklearn.cluster import KMeans
import numpy as np

X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])

kmeans = KMeans(n_clusters=2, random_state=0, n_init="auto").fit(X)
kmeans.labels_

kmeans.predict([[0, 0], [12, 3]])

kmeans.cluster_centers_
```

# [[æ¼”ç®—æ³•] K-means åˆ†ç¾¤ (K-means Clustering)](https://ithelp.ithome.com.tw/articles/10209058)
```python
import numpy as np
import matplotlib.pyplot as plt

# ç¾¤é›†ä¸­å¿ƒå’Œå…ƒç´ çš„æ•¸é‡
seed_num = 3
dot_num = 20

# åˆå§‹å…ƒç´ 
x = np.random.randint(0, 500, dot_num)
y = np.random.randint(0, 500, dot_num)
# åˆå§‹ç¾¤é›†ä¸­å¿ƒ
kx = np.random.randint(0, 500, seed_num)
ky = np.random.randint(0, 500, seed_num)


# å…©é»ä¹‹é–“çš„è·é›¢
def dis(x, y, kx, ky):
    return int(((kx-x)**2 + (ky-y)**2)**0.5)

# å°æ¯ç­†å…ƒç´ é€²è¡Œåˆ†ç¾¤
def cluster(x, y, kx, ky):
    team = []
    for i in range(3):
        team.append([])
    mid_dis = 99999999
    for i in range(dot_num):
        for j in range(seed_num):
            distant = dis(x[i], y[i], kx[j], ky[j])
            if distant < mid_dis:
                mid_dis = distant
                flag = j
        team[flag].append([x[i], y[i]])
        mid_dis = 99999999
    return team

# å°åˆ†ç¾¤å®Œçš„å…ƒç´ æ‰¾å‡ºæ–°çš„ç¾¤é›†ä¸­å¿ƒ
def re_seed(team, kx, ky):
    sumx = 0
    sumy = 0
    new_seed = []
    for index, nodes in enumerate(team):
        if nodes == []:
            new_seed.append([kx[index], ky[index]])
        for node in nodes:
            sumx += node[0]
            sumy += node[1]
        new_seed.append([int(sumx/len(nodes)), int(sumy/len(nodes))])
        sumx = 0
        sumy = 0
    nkx = []
    nky = []
    for i in new_seed:
        nkx.append(i[0])
        nky.append(i[1])
    return nkx, nky

# k-means åˆ†ç¾¤
def kmeans(x, y, kx, ky, fig):
    team = cluster(x, y, kx, ky)
    nkx, nky = re_seed(team, kx, ky)
    
    # plot: nodes connect to seeds
    cx = []
    cy = []
    line = plt.gca()
    for index, nodes in enumerate(team):
        for node in nodes:
            cx.append([node[0], nkx[index]])
            cy.append([node[1], nky[index]])
        for i in range(len(cx)):
            line.plot(cx[i], cy[i], color='r', alpha=0.6)
        cx = []
        cy = []
    
    # ç¹ªåœ–
    feature = plt.scatter(x, y)
    k_feature = plt.scatter(kx, ky)
    nk_feaure = plt.scatter(np.array(nkx), np.array(nky), s=50)
    plt.savefig('/yourPATH/kmeans_%s.png' % fig)
    plt.show()

    # åˆ¤æ–·ç¾¤é›†ä¸­å¿ƒæ˜¯å¦ä¸å†æ›´å‹•
    if nkx == list(kx) and nky == (ky):
        return
    else:
        fig += 1
        kmeans(x, y, nkx, nky, fig)


kmeans(x, y, kx, ky, fig=0)
```
#  KMeans
- [Hands-On Ensemble Learning with Python: Build highly optimized ensemble machine learning models using scikit-learn and Keras](https://www.packtpub.com/product/hands-on-ensemble-learning-with-python/9781789612851) [GITHUB](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python)
  - ç¹é«”ä¸­è­¯æœ¬[é›†æˆå¼å­¸ç¿’ï¼šPython å¯¦è¸ï¼æ•´åˆå…¨éƒ¨æŠ€è¡“ï¼Œæ‰“é€ æœ€å¼·æ¨¡å‹](https://www.tenlong.com.tw/products/9789863126942?list_name=srh) CH8-2
```PYTHON
import matplotlib.pyplot as plt
import numpy as np

from sklearn.cluster import KMeans
from sklearn.datasets import load_breast_cancer
from sklearn.manifold import TSNE


np.random.seed(123456)

bc = load_breast_cancer()
tsne = TSNE()

data = tsne.fit_transform(bc.data)
reds = bc.target == 0
blues = bc.target == 1
plt.scatter(data[reds, 0], data[reds, 1], label='malignant')
plt.scatter(data[blues, 0], data[blues, 1], label='benign')
plt.xlabel('1st Component')
plt.ylabel('2nd Component')
plt.title('Breast Cancer dataa')
plt.legend()


plt.figure()
plt.title('2, 4, and 6 clusters.')
for clusters in [2, 4, 6]:
    km = KMeans(n_clusters=clusters)
    preds = km.fit_predict(data)
    plt.subplot(1, 3, clusters/2)
    plt.scatter(*zip(*data), c=preds)

    classified = {x: {'m': 0, 'b': 0} for x in range(clusters)}

    for i in range(len(data)):
        cluster = preds[i]
        label = bc.target[i]
        label = 'm' if label == 0 else 'b'
        classified[cluster][label] = classified[cluster][label]+1

    print('-'*40)
    for c in classified:
        print('Cluster %d. Malignant percentage: ' % c, end=' ')
        print(classified[c], end=' ')
        print('%.3f' % (classified[c]['m'] /
                        (classified[c]['m'] + classified[c]['b'])))

    print(metrics.homogeneity_score(bc.target, preds))
    print(metrics.silhouette_score(data, preds))
```




